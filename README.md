# Telegram News Summary Bot

## Описание

Этот Telegram-бот предназначен для парсинга сообщений из Telegram-каналов и предоставления пользователю сводки новостей по интересующим темам. Пользователь может добавлять каналы, на которые он подписан, и запрашивать сводки новостей за различные периоды времени.

## Функциональность MVP

*   **Главное меню**: Кнопки "Показать список чатов", "Добавить канал".
*   **Просмотр списка чатов**: Вывод списка добавленных каналов с возможностью выбора чата для работы.
*   **Добавление канала**: Возможность добавить новый Telegram-канал в список отслеживаемых.
*   **Сводка новостей**: Получение сводки новостей из выбранного канала за определенный период (неделя, месяц, год, пользовательский период).
*   **Задание вопроса**: Возможность задать вопрос боту по текущему выбранному чату (функциональность обработки вопросов не реализована в MVP).

## Технологии

*   **Python**: Основной язык программирования.
*   **aiogram**: Асинхронный фреймворк для создания Telegram-ботов.
*   **SQLAlchemy (Async SQLAlchemy)**: ORM для работы с базой данных PostgreSQL асинхронно.
*   **asyncpg**: Асинхронный драйвер для PostgreSQL.
*   **PostgreSQL**: Реляционная база данных для хранения данных бота.
*   **python-dotenv**: Для управления конфигурацией и переменными окружения.
*   **sentence-transformers**: Для создания векторных представлений текста сообщений (embeddings).
*   **telethon**: Библиотека для работы с Telegram API (для парсинга каналов).

## Структура проекта

## ML Pipeline (Обучение NER модели)

Этот раздел описывает текущий процесс обучения модели NER (Named Entity Recognition), используемой в проекте.

**Шаги для запуска пайплайна:**

1.  **Подготовка данных:**
    *   Запускается скрипт `Learning_data.py`. Он загружает исходные данные (уточните источник, если необходимо) и создает промежуточную выборку.
    *   Запускается скрипт `clean_arrays.py`. Он очищает данные, полученные на предыдущем шаге, и сохраняет их в файл `TEST_DATA_NOTNA_CLEAN.txt`.

2.  **Конвертация в формат spaCy:**
    *   (Предположительно выполняется вручную или через ноутбук). Очищенные данные из `TEST_DATA_NOTNA_CLEAN.txt` конвертируются в бинарный формат spaCy (`.spacy`). Обычно создаются файлы для обучающей (`train.spacy`) и валидационной (`dev.spacy` или используется `train.spacy` для обеих, как в вашем примере) выборок.
    *   *Примечание:* Команда для запуска обучения (`python -m spacy train...`) ожидает наличие этих `.spacy` файлов.

3.  **Обучение модели:**
    *   Используется конфигурационный файл `config.cfg` для параметров обучения.
    *   Запустите следующую команду из корневой папки `Chapa`:
        ```bash
        python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy
        ```
        *   `config.cfg`: Основной файл конфигурации для spaCy.
        *   `--output ./output`: Указывает папку для сохранения обученных моделей (`model-best`, `model-last`).
        *   `--paths.train ./train.spacy`: Путь к обучающей выборке в формате spaCy.
        *   `--paths.dev ./dev.spacy`: Путь к валидационной выборке в формате spaCy. (Если валидационной нет, можно указать `--paths.dev ./train.spacy`, но это не рекомендуется для надежной оценки).

4.  **Результат:**
    *   Обученные модели (лучшая и последняя итерации) сохраняются в папку `output/`.
    *   Логи процесса обучения выводятся в консоль.

**Зависимости:**
*   Убедитесь, что у вас установлены `spacy` и языковая модель (например, `ru_core_news_lg` или та, что указана в `config.cfg`). Установка описана в разделе "Установка и запуск".

# ML System Design Document

## Раздел 1.6: Бизнес-ограничения и бизнес-риски

### Ограничения
1. **Юридические ограничения**:  
   - Соблюдение GDPR при обработке данных из Telegram-каналов.  
   - Ограничения Telegram API на парсинг (лимит: 100 сообщений/сек).  
2. **Ограничения на модель**:  
   - Интерпретируемость NER-модели для юридических текстов.  
   - Ограничение Gemini 2.0 на размер входных данных (макс. 10 тыс. токенов).  
3. **Временные ограничения**:  
   - Hard deadline: запуск MVP к 1 сентября.  
   - Сроки: POC (2 недели), MVP (3 месяца), пилот (6 месяцев).  

### Допущения
1. **О поведении клиентов**:  
   - Пользователи формулируют запросы с ключевыми сущностями.  
   - 80% пользователей готовы платить за Pro при точности >85%.  
2. **О бизнес-среде**:  
   - Конкуренты не внедрят аналогичный NLP-пайплайн в ближайшие 6 месяцев.  

### Риски
1. **Влияние ограничений**:  
   - Задержки из-за лимитов Telegram API (+30% к срокам).  
2. **Проблемы со сроками**:  
   - Задержки согласований с юристами (GDPR).  
3. **Риски отмены проекта**:  
   - Смена приоритетов бизнеса.  
   - Появление конкурента на базе ChatGPT.  

---

## Раздел 2: Solution Design

### 2.1 Данные
1. **Источники данных**:  
   - Telegram-каналы (10 тыс. сообщений/день), внешние сайты (Pro-тариф).  
2. **Формат данных**:  
   - Текстовые сообщения , эмбеддинги (768d), сущности (NER).  
3. **Ручная разметка**:  
   - Валидация 5% данных (F1-score >90%).  
4. **Качество данных**:  
   - Проблемы: шум, устаревшие данные (>6 месяцев).  

### 2.2 Технические ограничения и риски
1. **Инфраструктура**:  
   - GPU-серверы (NVIDIA A100), RAM 64 ГБ.  
2. **Скорость ответа**:  
   - ≤1.5 сек на запрос.  
3. **Интеграции**:  
   - Зависимость от Langchain.  

### 2.3 Функциональные и нефункциональные требования
| **Тип**              | **Требования**                                                                 |
|-----------------------|-------------------------------------------------------------------------------|
| Функциональные        | Поиск по семантике, ранжирование новостей, подключение внешних сайтов (Pro). |
| Нефункциональные      | Обработка 100 запросов/сек, масштабируемость до 1 млн пользователей, TLS 1.3. |

### 2.4 Архитектура решения
1. **Компоненты**:  
   - Парсер → PostgreSQL → NLP-пайплайн → Gemini 2.0 → FastAPI.  
2. **Потоки данных**:  
   ```mermaid
   graph LR
   A[Парсинг] --> B[Очистка] --> C[Векторизация] --> D[Хранение] --> E[Поиск]

# Data Science Methodology

## 3.1. Постановка ML-задачи и выбор подхода
### ML-формулировка задачи
- **Тип задачи**: Sequence Labeling (последовательная разметка токенов).
- **Целевое событие**: Классификация каждого токена в текстe как:
  - `B-PER` (начало персоны)
  - `I-PER` (продолжение персоны)
  - `B-ORG` (начало организации)
  - ... и т.д.
- **Метрика оптимизации**: **F1-score** (микро-усреднение для многоклассовой задачи).

### Бейзлайн и альтернативы
| **Подход**               | **Плюсы**                          | **Минусы**                     | **Выбор** |
|--------------------------|------------------------------------|--------------------------------|-----------|
| Ключевые слова           | Быстро, интерпретируемо            | Низкая точность                | ❌         |
| SpaCy (предобученная)    | Готовое решение                    | Не адаптирована к домену       | ✅         |
| BERT-based NER           | Высокая точность                   | Высокие ресурсы                | ❌         |

---

## 3.2. Обучающие данные
### Формирование выборки
- **Источники данных**: 
  - 10,000 сообщений из 50 Telegram-каналов (парсинг через Telethon).
  - Ручная разметка 500 сообщений (5%) с помощью Prodigy.
- **Аугментация**: 
  - Замена синонимов (WordNet).
  - Добавление шума (орфографические ошибки).

### Признаки (Feature Engineering)
| **Тип признака**         | **Пример**                         |
|--------------------------|------------------------------------|
| Токен                    | "ИИ"                              |
| Часть речи               | "NOUN"                            |
| Контекстные эмбеддинги   | BERT-вектор токена                |
| Суффикс/префикс          | "искусственный" → "искусственн**ый**" |

### Обработка данных
1. **Очистка**: 
   - Удаление дубликатов.
   - Нормализация текста (lowercase, стемминг).
2. **Балансировка**: 
   - Веса классов для борьбы с дисбалансом (например, `class_weight='balanced'`).

---

## 3.3. Методы и алгоритмы
### Выбор модели
- **Архитектура**: SpaCy Transformer (`ru_core_news_lg`) + дообучение.
- **Обоснование**: 
  - Эффективность на русском языке.
  - Поддержка кастомных сущностей.

### Гиперпараметры
| **Параметр**      | **Значение**                      | **Стратегия оптимизации**      |
|--------------------|-----------------------------------|--------------------------------|
| Learning Rate      | 3e-5 → 1e-4                      | GridSearch                     |
| Batch Size         | 16 → 32                          | Поиск по сетке                 |
| Dropout            | 0.2 → 0.5                        | Адаптация под переобучение     |

---

## 3.4. Валидация и оценка качества
### Стратегия валидации
- **Разделение данных**: 
  - Train (70%) / Validation (15%) / Test (15%).
  - Стратификация по классам сущностей.
- **Кросс-валидация**: 5-fold для оценки стабильности модели.

### Метрики качества
| **Метрика**         | **Целевое значение** | **Интерпретация**              |
|---------------------|----------------------|--------------------------------|
| F1-score (микро)    | ≥ 0.90               | Основной критерий              |
| Precision           | ≥ 0.85               | Минимизация ложных срабатываний|
| Recall              | ≥ 0.88               | Покрытие релевантных сущностей |

### Принятие решения
- **Критерий готовности**: 
  - F1-score > 0.90 на тестовой выборке.
  - Отчет по ошибкам: анализ 100 случайных ошибок (например, путаница между `ORG` и `PRODUCT`).
- **Демонстрация стейкхолдерам**: 
  - Визуализация через displacy (примеры разметки).
  - ROI: Экономия 50% времени на поиск информации.

---

## Примечания
- **Интерпретация**: LIME для объяснения предсказаний ключевых сущностей.
- **Мониторинг**: Еженедельное обновление модели на новых данных.